{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cGmGhEhc-9tv"
   },
   "source": [
    "# PyTorch Tensors\n",
    "\n",
    "In order to get anything done with deep learning, we need some way to store and manipulate data. \n",
    "Therefore, to start, we develop proficiency with the n-dimensional array in PyTorch, which is also called the tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "ditQAfhTXy3l"
   },
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hDOSz3QVaSbe"
   },
   "source": [
    "### Exercise 1A:\n",
    "Create in the next code cell a 32-bit floating point torch Tensor of shape `(4,5)` which is filled with square root of 29."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "PTTRn9HFeG9U"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[5.3852, 5.3852, 5.3852, 5.3852, 5.3852],\n",
       "        [5.3852, 5.3852, 5.3852, 5.3852, 5.3852],\n",
       "        [5.3852, 5.3852, 5.3852, 5.3852, 5.3852],\n",
       "        [5.3852, 5.3852, 5.3852, 5.3852, 5.3852]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor = torch.full((4, 5), torch.sqrt(torch.tensor(29.0)), dtype=torch.float32)\n",
    "tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cxQKhClJ427n"
   },
   "source": [
    "### Exercise 1B:\n",
    "\n",
    "Convert the tensor created in the previous exercise to 64-bit floating point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "gTnfu78t5OTJ"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[5.3852, 5.3852, 5.3852, 5.3852, 5.3852],\n",
       "        [5.3852, 5.3852, 5.3852, 5.3852, 5.3852],\n",
       "        [5.3852, 5.3852, 5.3852, 5.3852, 5.3852],\n",
       "        [5.3852, 5.3852, 5.3852, 5.3852, 5.3852]], dtype=torch.float64)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor = tensor.to(dtype=torch.float64)\n",
    "tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M1Teyrxoa-bl"
   },
   "source": [
    "### Exercise 2:\n",
    "Create a tensor `x` (you can give it the shape you want) such that its elements are sampled from a normal distribution of mean 3 and variance 2.\n",
    "\n",
    "Next, create a tensor `y` having the same shape as `x` such that its elements are sampled from a uniform distribution between -1 and 2. Your code should be robust to the shape of `x` such that if you change the shape of `t`, the shape of your `y` should adapt!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "IQVraHuJa9yJ"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1.4745, 1.0296, 1.0502, 2.8298],\n",
       "         [1.4752, 3.2231, 1.6685, 3.7533],\n",
       "         [0.5909, 3.2739, 1.7187, 4.1239]]),\n",
       " tensor([[ 1.2772,  0.3217, -0.2400, -0.7849],\n",
       "         [ 0.9439,  0.8879,  1.8247,  0.2922],\n",
       "         [-0.8566,  1.0425,  1.4151, -0.9638]]))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.normal(mean=3.0, std=torch.sqrt(torch.tensor(2.0)), size=(3, 4))\n",
    "y = torch.distributions.Uniform(-1, 2).sample(x.shape)\n",
    "x,y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tEdNH8f_aMaq"
   },
   "source": [
    "### Exercise 3:\n",
    "\n",
    "Run `A / A.sum(axis=1)` for the following tensor A and see what happens. Can you analyze the reason? Create a text cell to provide your answer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "NkW8P7eRaU_G"
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (5) must match the size of tensor b (4) at non-singleton dimension 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_1856324/3965034279.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mA\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mA\u001b[0m\u001b[0;34m/\u001b[0m \u001b[0mA\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (5) must match the size of tensor b (4) at non-singleton dimension 1"
     ]
    }
   ],
   "source": [
    "A = torch.arange(20, dtype=torch.float32).reshape(4, 5)\n",
    "A/ A.sum(axis=1)\n",
    "A"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are trying to divide a (4, 5) tensor (2D) by a (4,) tensor (1D), which cannot be broadcast directly across columns. If the sum shape is (4,1) it would then be possible to perform row division across columns."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d3_3bYqPbl16"
   },
   "source": [
    "### Exercise 4:\n",
    "\n",
    "As with an ordinary Python array, we can access the length of a tensor by calling Python’s built-in `len()` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "f374NfPgbfx2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.arange(4)\n",
    "len(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VbleR1jrbFqW"
   },
   "source": [
    "We now define a tensor `X` of shape `(2, 3, 4)` . What is the output of `len(X)`? Can you analyse the reason for the output? Create a text cell to provide your answer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "sa_dP5PSa1fX"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = torch.arange(24).reshape(2, 3, 4)\n",
    "len(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output is 2 because len(X) always returns the size of the first dimension of the tensor, which corresponds to the number of 2D matrices in the 3D tensor."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PemQ00mUdp9Q"
   },
   "source": [
    "### Exercise 5:\n",
    "\n",
    "We have seen examples of PyTorch `Tensor` broadcasting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "s546kHtZd8Et"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([3, 1]), torch.Size([5]))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.arange(3).reshape((3, 1))\n",
    "b = torch.arange(5)\n",
    "a.shape, b.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "_VlSi8gkd-Jc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 1, 2, 3, 4],\n",
       "        [1, 2, 3, 4, 5],\n",
       "        [2, 3, 4, 5, 6]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a + b\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TePM4O49eFWI"
   },
   "source": [
    "Replace the two tensors in the broadcasting mechanism with different shapes of 3 or 4-dimensional tensors. For example `a = torch.empty(5,2,4,1)`,\n",
    "`b = torch.empty(3,1,1)`. Is the result the same as expected? Analyse the results. Come up with 3D or 4D tensors with different sizes at each dimension. Can you come up with the rules with examples which are required for Tensor broadcasting to work? Creat a text block to provide your analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([5, 2, 4, 1]), torch.Size([3, 1, 1]))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.empty(5, 2, 4, 1)\n",
    "b = torch.empty(3, 1, 1)\n",
    "\n",
    "a.shape , b.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (2) must match the size of tensor b (3) at non-singleton dimension 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_1099386/3553919051.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0ma\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (2) must match the size of tensor b (3) at non-singleton dimension 1"
     ]
    }
   ],
   "source": [
    "a+b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Broadcasting lets us perform operations on tensors of different shapes by automatically expanding their dimensions where possible. The rules are:\n",
    "\n",
    "- Start comparing shapes from the last dimension (from the end)\n",
    "- For each pair of dimensions:\n",
    "    - If they’re equal, that’s fine.\n",
    "    - If one of them is 1, that’s also fine (it can be stretched to match).\n",
    "    - If neither of these is true, the tensors can’t be broadcasted.\n",
    "\n",
    "- If one tensor has fewer dimensions, it’s treated as if it has extra 1s on the left.\n",
    "\n",
    "\n",
    "Example 1: \n",
    "- Tensors a: (5, 2, 4, 1), b: (2, 1, 1)\n",
    "- Aligning shapes from the end:\n",
    "    a: 5  2  4  1  \n",
    "    b:    2  1  1  <-- implicitly becomes (1, 2, 1, 1)\n",
    "- Since all dimensions are compatible, b will be broadcasted to match a: (5, 2, 4, 1)\n",
    "\n",
    "Example 2:\n",
    "- Tensors a: (5, 2, 4, 1), b: (3, 1, 1) as seen in the previous cell. The reason we got the unexpected output will be clear when we align shapes from the end:\n",
    "    1 vs 1 -> Ok\n",
    "    4 vs 1 -> Ok\n",
    "    2 vs 3 -> Not compatible (neither is 1 nor equal)\n",
    "\n",
    "Hence we get the output."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pOJzmeyQj_Y-"
   },
   "source": [
    "### Exercise 6:\n",
    "\n",
    "Create a one dimensional tensor `x` containing the numbers `0` to `23` in order.\n",
    "Reshape x in the next code cell to create the following tensor:\n",
    "\n",
    "```\n",
    "tensor([[ 0,  1,  2,  3, 12, 13, 14, 15],\n",
    "             [ 4,  5,  6,  7, 16, 17, 18, 19],\n",
    "             [ 8,  9, 10, 11, 20, 21, 22, 23]])\n",
    "```\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "jSKEKVJWk7qG"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0,  1,  2,  3, 12, 13, 14, 15],\n",
       "        [ 4,  5,  6,  7, 16, 17, 18, 19],\n",
       "        [ 8,  9, 10, 11, 20, 21, 22, 23]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.arange(24)\n",
    "#x\n",
    "x_re = torch.cat([\n",
    "    x[:12].reshape(3, 4),   # elements 0–11 with 3 rows, 4 columns\n",
    "    x[12:].reshape(3, 4)    # elements 12–23 with 3 rows, 4 columns\n",
    "], dim=1)  # concatenate them\n",
    "x_re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pAwL3IAdmIze"
   },
   "source": [
    "### Exercise 7:\n",
    "\n",
    "A one-hot vector for an integer $n$ is a vector that has a one in its $n$th slot, and zeros in all other slots. One-hot vectors are used to represent categorical variables in machine learning.\n",
    "\n",
    "Implement a function in the following code cell that creates a 2D PyTorch tensor of one-hot row vectors from a list of Python integers.\n",
    "\n",
    "For example, given a list `[1, 2, 3, 3]` of integers, your function should produce the 2D tensor:\n",
    "\n",
    "```\n",
    "[[0 1 0 0],\n",
    " [0 0 1 0],\n",
    " [0 0 0 1],\n",
    " [0 0 0 1]]\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "HhOt0ZBLm7Ul"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 1., 0., 0.],\n",
      "        [0., 0., 1., 0.],\n",
      "        [0., 0., 0., 1.],\n",
      "        [0., 0., 0., 1.]])\n"
     ]
    }
   ],
   "source": [
    "def one_hot_vector(x):\n",
    "  num_classes = max(x) + 1\n",
    "  one_hot_vectors = torch.zeros((len(x), num_classes))\n",
    "  for i, integer in enumerate(x):\n",
    "    one_hot_vectors[i][integer] = 1\n",
    "  return one_hot_vectors\n",
    "\n",
    "x = [1, 2, 3, 3]\n",
    "print(one_hot_vector(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C1rvW5Groxjk"
   },
   "source": [
    "### Exercise 8:\n",
    "\n",
    "Use the GPU to accelerate multiplication of the following large 2D PyTorch tensors. First perform the multiplication on CPU. Next perform the computation on GPU. Compare the time required for mulplication on CPU vs GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "htsK3scgpI2o"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU time: 138.66188049316406 ms\n",
      "GPU time: 4.7409281730651855 ms\n"
     ]
    }
   ],
   "source": [
    "x = torch.rand(1024, 4096) # 2 random tensors\n",
    "y = torch.rand(4096, 8192)\n",
    "start = torch.cuda.Event(enable_timing=True)\n",
    "end = torch.cuda.Event(enable_timing=True)\n",
    "\n",
    "start.record()\n",
    "result_cpu = torch.matmul(x, y)\n",
    "end.record()\n",
    "torch.cuda.synchronize()\n",
    "print(f\"CPU time: {start.elapsed_time(end)} ms\")\n",
    "\n",
    "x = x.cuda()\n",
    "y = y.cuda()\n",
    "\n",
    "start.record()\n",
    "result_gpu = torch.matmul(x, y)\n",
    "end.record()\n",
    "torch.cuda.synchronize()\n",
    "print(f\"GPU time: {start.elapsed_time(end)} ms\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w-8RSk8_rCAF"
   },
   "source": [
    "### Exercise 9: \n",
    "\n",
    "Create a function to compute the number of negative values in a tensor.\n",
    "Your code should not use any loops. After implementing the function, test your function with input PyTorch tensors of different shapes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "ATNJZuj8rZO3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Negative values in x1: 3\n",
      "Negative values in x2: 4\n",
      "Negative values in x3: 24\n"
     ]
    }
   ],
   "source": [
    "def negative_value_count(x):\n",
    "  # pass # replace pass with your code\n",
    "    return (x < 0).sum().item() \n",
    "\n",
    "x1 = torch.tensor([[1, -2, 3], [-4, 5, -6]])  #test\n",
    "x2 = torch.tensor([[-1, 2, 3], [4, -5, 6], [-7, 8, -9]])\n",
    "x3 = torch.randn(10, 5)\n",
    "\n",
    "\n",
    "print(f\"Negative values in x1: {negative_value_count(x1)}\")\n",
    "print(f\"Negative values in x2: {negative_value_count(x2)}\")\n",
    "print(f\"Negative values in x3: {negative_value_count(x3)}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "IV_0MpGnscrH"
   },
   "source": [
    "### Exercise 10:\n",
    "\n",
    "Create a function which returns the copy of the input tensor but with maximum value along each column set to `-1`.\n",
    "\n",
    "  For example:\n",
    "\n",
    "```\n",
    " x = torch.tensor([\n",
    "        [12, 21, 1],\n",
    "        [ 4,  7,  20]\n",
    "      ])\n",
    "```\n",
    "\n",
    "\n",
    "  Then `y = negative_max_column(x)` should be:\n",
    " \n",
    "  ```\n",
    "torch.tensor([\n",
    "    [-1, -1, 1],\n",
    "    [4,  7,  -1]\n",
    "  ])\n",
    "```\n",
    "\n",
    "\n",
    "Your code should not use any loops. Test your function with some examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "_PtT2PhPthot"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test 1 output:\n",
      "tensor([[-1, -1,  1],\n",
      "        [ 4,  7, -1]])\n",
      "\n",
      "Test 2 output:\n",
      "tensor([[-1, -1, -1],\n",
      "        [-1,  2, -1]])\n",
      "\n",
      "Test 3 output:\n",
      "tensor([[-1, -1, -3],\n",
      "        [-2, -1, -1],\n",
      "        [-1, -5, -1]])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def negative_max_column(x):\n",
    "  # pass # replace pass with your code\n",
    "    column_max, _ = torch.max(x, dim=0, keepdim=True)\n",
    "    neg = torch.where(x == column_max, torch.full_like(x, -1.0), x)\n",
    "    return neg\n",
    "\n",
    "\n",
    "#test 1\n",
    "x1 = torch.tensor([\n",
    "    [12, 21, 1],\n",
    "    [4, 7, 20]\n",
    "])\n",
    "\n",
    "#test 2\n",
    "x2 = torch.tensor([\n",
    "    [5, 8, 3],\n",
    "    [5, 2, 3]\n",
    "])\n",
    "\n",
    "#test 3\n",
    "x3 = torch.tensor([\n",
    "    [-1, 0, -3],\n",
    "    [-2, 0, 4],\n",
    "    [0, -5, 4]\n",
    "])\n",
    "\n",
    "test_tensors = [x1, x2, x3]\n",
    "\n",
    "for i, x in enumerate(test_tensors, 1):\n",
    "    y = negative_max_column(x)\n",
    "    print(f\"Test {i} output:\\n{y}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TqTMByiGzY5M"
   },
   "source": [
    "### Exercise 11:\n",
    "\n",
    "Write a function to subtract the mean of each row from a 2D tensor. Your code should not use any loops. Test your function with some examples.\n",
    "\n",
    "Example 1:\n",
    "For the following input tensor:\n",
    "`tensor([[1,0],[0,4]])`\n",
    "The desired output is the following:\n",
    "`tensor([[0.5000,−0.5000],[−2.0000,2.0000]])`\n",
    "\n",
    "Example 2:\n",
    "For the following input tensor:\n",
    "`tensor([[.5,0,0],[0,.3,0],[0,0,8]])`\n",
    "\n",
    "The desired output is the following:\n",
    "`tensor([[0.3333,−0.1667,−0.1667],[−0.1000,0.2000,−0.1000],[−2.6667,−2.6667,5.3333]])`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "iFSxG08czz-3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.5000, -0.5000],\n",
      "        [-2.0000,  2.0000]])\n",
      "tensor([[ 0.3333, -0.1667, -0.1667],\n",
      "        [-0.1000,  0.2000, -0.1000],\n",
      "        [-2.6667, -2.6667,  5.3333]])\n"
     ]
    }
   ],
   "source": [
    "def subtract_row_mean(x):\n",
    "  # pass # replace pass with your code\n",
    "    row_mean = torch.mean(x, dim=1, keepdim=True)  # (mean of each row ,1) dim for broadcasting\n",
    "    return x - row_mean\n",
    "\n",
    "#test\n",
    "x1 = torch.tensor([[1, 0], [0, 4]], dtype=torch.float32)\n",
    "y1 = subtract_row_mean(x1)\n",
    "print(y1)\n",
    "\n",
    "x2 = torch.tensor([[0.5, 0, 0], [0, 0.3, 0], [0, 0, 8]], dtype=torch.float32)\n",
    "y2 = subtract_row_mean(x2)\n",
    "print(y2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VwTLS7_P54eZ"
   },
   "source": [
    "### Exercise 12:\n",
    "\n",
    "Feed a tensor with 3 or more dimensions to the `linalg.norm` function and observe its output. What does this function compute for tensors of arbitrary shape? Explain in a block below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "vhnPvgz86AsK"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0.3659, 0.1557, 0.1604, 0.8375],\n",
      "         [0.5451, 0.2398, 0.0023, 0.4335],\n",
      "         [0.9359, 0.0206, 0.9614, 0.6242]],\n",
      "\n",
      "        [[0.6369, 0.8481, 0.7283, 0.0200],\n",
      "         [0.9259, 0.9430, 0.2128, 0.2967],\n",
      "         [0.8710, 0.1603, 0.9522, 0.5806]]])\n",
      "\n",
      "Norm: tensor(3.0302)\n"
     ]
    }
   ],
   "source": [
    "x = torch.rand(2, 3, 4)\n",
    "norm_x = torch.linalg.norm(x)\n",
    "\n",
    "print(x)\n",
    "print(\"\\nNorm:\", norm_x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "linalg.norm computes the norm of a matrix (if dim is a 2d tuple)/vector (if dim is int). There's customizations for the type of norm that can be computed. The torch.linalg.norm function calculates the Frobenius norm for tensors of arbitrary dimensions as follows:\n",
    "\n",
    "- Flatten the tensor into a 1D tensor.\n",
    "- Calculate the sum of the absolute squares of its elements.\n",
    "- Take the square root of the sum."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ON8rugsexuOY"
   },
   "source": [
    "### Exercise 13: \n",
    "\n",
    "Implement a function that takes in two $2 \\mathrm{D}$ tensors $A$ and $B$ and returns the column sum of A multiplied by the sum of all the elmements of $\\boldsymbol{B}$, i.e., a scalar, e.g.,\n",
    "If $A=\\left[\\begin{array}{ll}1 & 1 \\\\ 1 & 1\\end{array}\\right]$ and $B=\\left[\\begin{array}{lll}1 & 2 & 3 \\\\ 1 & 2 & 3\\end{array}\\right]$ then $O u t=\\left[\\begin{array}{ll}2 & 2\\end{array}\\right] \\cdot 12=\\left[\\begin{array}{ll}24 & 24\\end{array}\\right]$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "S5YVpsJLx9fO"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output for A * B is tensor([24, 24])\n",
      "Output for x1 * x2 is tensor([-27., -54., -81.])\n"
     ]
    }
   ],
   "source": [
    "def add_and_multiply(A,B):\n",
    "  A_col_sum = torch.sum(A, dim=0)\n",
    "  B_sum = torch.sum(B)\n",
    "  return A_col_sum * B_sum\n",
    "\n",
    "A = torch.tensor([\n",
    "    [1,1],\n",
    "    [1 ,1]\n",
    "    ])\n",
    "B = torch.tensor([\n",
    "    [1,2,3],\n",
    "    [1 ,2,3,]\n",
    "    ])\n",
    "output = add_and_multiply(A,B)\n",
    "print(f\"Output for A * B is {output}\")\n",
    "\n",
    "x1 = torch.tensor([\n",
    "    [1, 2, 3],\n",
    "    [1, 2, 3],\n",
    "    [1, 2, 3]\n",
    "],dtype=torch.float32)\n",
    "\n",
    "x2 = torch.tensor([\n",
    "    [-1, -1, -1],\n",
    "    [2, 2, 2],\n",
    "    [-4, -4, -4]\n",
    "],dtype=torch.float32)\n",
    "output_1 = add_and_multiply(x1,x2)\n",
    "print(f\"Output for x1 * x2 is {output_1}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G9sRzXzKx_UP"
   },
   "source": [
    "### Exercise 14:\n",
    "\n",
    "Implement a function that takes in a square matrix $A$ and returns a $2 D$ tensor consisting of a flattened $A$ with the index of each element appended to this tensor in the row dimension, e.g.,\n",
    "If $A=\\left[\\begin{array}{cc}2 & 3 \\\\ -1 & 10\\end{array}\\right]$ then $O u t=\\left[\\begin{array}{cc}0 & 2 \\\\ 1 & 3 \\\\ 2 & -1 \\\\ 3 & 10\\end{array}\\right]$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "gv0g3w5_yZzp"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.,  2.],\n",
       "        [ 1.,  3.],\n",
       "        [ 2., -1.],\n",
       "        [ 3., 10.]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def flaten_and_append(A):\n",
    "  assert A.shape[0] == A.shape[1]  #square matrix as input\n",
    "  indices = torch.arange(torch.numel(A)).reshape(-1,1)\n",
    "  A_flat = torch.flatten(A).reshape(-1,1)\n",
    "  output = torch.cat((indices, A_flat),dim=1)\n",
    "  return output\n",
    "\n",
    "A = torch.tensor([[2, 3],\n",
    "                  [-1, 10]], dtype=torch.float32)\n",
    "\n",
    "output = flaten_and_append(A)\n",
    "output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "prm8Wx65xqC5"
   },
   "source": [
    "### Exercise 15:\n",
    "\n",
    "Implement a function that takes in two $2 D$ tensors $A$ and $B$. If the shapes allow it, this function returns the elementwise sum of $A$-shaped $B$, and $B$; else this function returns a 1D tensor that is the concatenation of the two tensors, e.g.,\n",
    "If $A=\\left[\\begin{array}{cc}1 & -1 \\\\ -1 & 3\\end{array}\\right]$ and $B=\\left[\\begin{array}{llll}2 & 3 & 0 & 2\\end{array}\\right]$ then $O u t=\\left[\\begin{array}{cc}3 & 2 \\\\ -1 & 5\\end{array}\\right]$\n",
    "If $A=\\left[\\begin{array}{cc}1 & -1 \\\\ -1 & 3\\end{array}\\right]$ and $B=\\left[\\begin{array}{ccc}2 & 3 & 0\\end{array}\\right]$ then $O u t=\\left[\\begin{array}{ccccccc}1 & -1 & -1 & 3 & 2 & 3 & 0\\end{array}\\right]$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "di2J13g_zB9q"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 3.,  2.],\n",
      "        [-1.,  5.]])\n",
      "tensor([ 1., -1., -1.,  3.,  2.,  3.,  0.])\n"
     ]
    }
   ],
   "source": [
    "def combine_tensors(A, B):\n",
    "    try:\n",
    "        B_shaped = B.reshape(A.shape)\n",
    "        output = A + B_shaped\n",
    "    except RuntimeError:\n",
    "        output = torch.cat((A.flatten(), B.flatten()))\n",
    "    return output\n",
    "\n",
    "A1 = torch.tensor([[1, -1],\n",
    "                   [-1, 3]], dtype=torch.float32)\n",
    "\n",
    "B1 = torch.tensor([2, 3, 0, 2], dtype=torch.float32)\n",
    "\n",
    "output1 = combine_tensors(A1, B1)\n",
    "print(output1)\n",
    "\n",
    "A2 = torch.tensor([[1, -1],\n",
    "                   [-1, 3]], dtype=torch.float32)\n",
    "\n",
    "B2 = torch.tensor([2, 3, 0], dtype=torch.float32)\n",
    "\n",
    "output2 = combine_tensors(A2, B2)\n",
    "print(output2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "a0AW0MgM2IeW"
   },
   "source": [
    "### Exercise 16:\n",
    "\n",
    "You are given a tensor `samples` with 12 sequences of length 15. Adapt the code below to add a `new_sample` to `samples` tensor.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "lP6teQMI2H-C"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-5.1355e-01,  2.4170e+00,  1.6826e-01,  1.6043e+00,  7.1901e-01,\n",
       "         -1.1538e-02,  8.6024e-01,  1.6311e+00,  3.0585e-01,  8.7563e-01,\n",
       "         -7.5413e-01, -1.5059e+00, -2.4381e+00, -1.8494e-01, -1.4239e-01],\n",
       "        [-3.8149e-01,  3.0317e-01, -5.8626e-01, -1.2470e+00,  1.8724e+00,\n",
       "          1.1002e+00, -4.9279e-01, -4.2162e-01,  3.3764e-01, -2.5314e-01,\n",
       "          6.8918e-01, -1.0707e+00, -3.9977e-01, -7.9596e-01, -2.5736e-01],\n",
       "        [-3.0031e-01,  5.6112e-01, -3.6882e-01, -1.4406e-01, -2.9724e-01,\n",
       "          1.3576e+00, -8.4231e-01, -1.5052e+00,  4.1953e-02, -6.1958e-01,\n",
       "         -1.6105e+00,  5.4606e-01,  1.0497e+00,  4.0686e-01,  1.2197e+00],\n",
       "        [-1.3175e+00,  7.8250e-02, -5.1606e-01, -1.6556e-01,  1.4412e+00,\n",
       "          1.0966e+00,  1.1626e+00, -1.2632e+00, -8.4339e-01,  2.0194e-01,\n",
       "         -9.9883e-01,  8.9911e-01, -2.3282e-01,  1.8972e+00, -6.8810e-01],\n",
       "        [-1.3735e+00,  1.3747e+00,  2.0008e-02,  1.2616e-01,  2.1671e+00,\n",
       "         -7.2217e-01,  5.9229e-02, -1.4764e+00,  5.5355e-01, -8.1631e-03,\n",
       "          7.2751e-01,  1.1006e+00,  3.9015e-01, -6.2705e-01,  1.3141e+00],\n",
       "        [ 9.3800e-01, -6.7659e-01,  5.3761e-01,  1.0994e+00,  3.1622e-01,\n",
       "         -7.8455e-01, -2.2315e-01, -1.3631e+00,  1.8451e-01,  6.7974e-01,\n",
       "         -6.3635e-02, -2.0276e-03, -5.8298e-01, -2.1469e-02,  7.0061e-01],\n",
       "        [ 9.4405e-02, -8.5966e-01, -1.2223e+00,  1.2637e-01,  3.6433e-01,\n",
       "         -1.2943e+00,  9.0327e-01, -5.9412e-01, -7.5826e-01,  5.9155e-01,\n",
       "         -8.6410e-01, -7.7231e-01, -1.6362e+00,  5.1931e-01,  1.0070e+00],\n",
       "        [ 3.8744e-02,  2.1171e+00,  3.3686e-01,  9.6449e-01, -7.4537e-01,\n",
       "          1.2194e+00,  1.2119e+00,  2.5563e+00,  1.3765e+00,  5.0138e-02,\n",
       "         -9.3861e-01,  1.9362e+00,  2.4693e-01,  1.0676e-02, -8.8891e-01],\n",
       "        [-1.4573e+00, -2.0151e+00, -1.7013e+00,  6.4495e-02,  2.0327e+00,\n",
       "         -7.5479e-02, -5.5854e-01,  1.5662e+00, -9.4751e-01,  4.1746e-01,\n",
       "         -1.9954e-01,  2.1977e+00,  9.9641e-01,  1.4825e-01,  1.1325e+00],\n",
       "        [-3.8065e-01,  5.9799e-02, -1.5310e+00,  1.2443e+00, -8.7613e-02,\n",
       "         -7.0924e-01,  2.3257e-01,  5.8237e-02,  1.1330e+00,  2.4749e-01,\n",
       "          7.1915e-01,  7.7637e-01, -4.2616e-01,  7.1614e-01, -5.5685e-01],\n",
       "        [ 1.7999e-01, -4.6577e-01,  8.8892e-01, -3.0508e-01, -7.1942e-01,\n",
       "         -9.2235e-01, -7.3008e-01, -1.4641e+00, -3.3960e-01, -1.3834e+00,\n",
       "         -6.7112e-01, -1.3700e-01,  5.8633e-01,  5.0380e-01,  2.3809e-01],\n",
       "        [-2.4398e+00, -4.6691e-01, -3.5564e-01, -2.5190e-01,  1.1687e+00,\n",
       "          2.6469e-01,  9.5794e-02,  1.6428e+00,  1.2324e+00,  5.6447e-02,\n",
       "          2.7515e-01,  2.3407e-01,  4.2060e-02, -1.1979e-01,  1.2991e-01],\n",
       "        [ 1.3194e+00, -1.7050e+00,  5.1840e-01,  1.0486e+00, -1.2152e+00,\n",
       "          2.9833e-01,  2.9725e-01, -6.7415e-01,  6.2768e-01, -3.9796e-01,\n",
       "         -7.2394e-01, -2.2375e+00, -1.4152e+00,  1.3894e+00,  2.5099e-01]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "samples = torch.randn(size=(12, 15))\n",
    "new_sample = torch.randn(size=(15,))\n",
    "\n",
    "new_sample = new_sample.unsqueeze(0) #add dim 1 to the new_sample tensor\n",
    "samples = torch.cat((samples, new_sample), dim=0)\n",
    "samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZHbGP9G6zqp5"
   },
   "source": [
    "### Exercise 17:\n",
    "\n",
    "Suppose you have a tensor `images_tensor` containing  a batch of `n_batch` number of images of resolution: 30x30 pixels. `images_tensor` is thus of shape `(n_batch, 1, 30, 30)`\n",
    "\n",
    "Write a function `flatten_images` that convert `images_tensor` into a tensor containing flattened images (i.e. a tensor of shape: `(n_batch, 1*30*30)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "l-nkDUOV0qEb"
   },
   "outputs": [],
   "source": [
    "def flatten_images(images_tensor):\n",
    "    # images_tensor shape: (batch_size, channels, height, width)\n",
    "    n_batch, c, h, w = images_tensor.shape\n",
    "    # Flatten each image into a vector: (batch_size, channels*height*width)\n",
    "    flattened_img_tensor = images_tensor.view(n_batch, -1)\n",
    "    return flattened_img_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 900])\n"
     ]
    }
   ],
   "source": [
    "n_batch = 5\n",
    "images_tensor = torch.randn(size=(n_batch, 1, 30, 30))\n",
    "flattened_images = flatten_images(images_tensor)\n",
    "print(flattened_images.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "assignment_1A.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
